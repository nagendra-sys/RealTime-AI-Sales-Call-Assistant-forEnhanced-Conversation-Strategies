MODULE - 1 
1. What is Generative AI?
      Generative AI is a subset of artificial intelligence that focuses on creating new content, such as text, images, music, or videos, by analyzing and learning from patterns in existing data.

2. How does Generative AI work?
      Generative AI works by training deep learning models, like neural networks, on large datasets. These models learn patterns, relationships, and structures in the data, enabling them to generate new content that resembles the training data.

3. What are the Use Cases of Generative AI?
      Image Synthesis: Creating realistic or artistic images.
      Text Generation: Chatbots, content creation, and translation.
      Music Composition: Generating original melodies and harmonies.
      Game Design: Procedural content generation for dynamic experiences.
      Medical Imaging: Enhancing and generating synthetic medical images.
      Deepfakes: Synthesizing realistic videos with ethical considerations.

4. Is ChatGPT, a chatbot, or Alexa generative AI?
      ChatGPT: Yes, it is generative AI.
      Chatbots: Not all are generative; some use rule-based systems.
      Alexa: Partially uses generative AI but mainly relies on rule-based systems.

5. What are the ethical considerations in generative AI?
      Ethical concerns include potential misuse, creation of deceptive content, privacy violations, biased outputs, and ensuring responsible, transparent deployment.

6. Can generative AI generate biased content?
      Yes, if trained on biased datasets, generative AI may produce biased outputs. Addressing and curating training data is essential to mitigate this risk.

7. Can generative AI replace human creativity?
      No, generative AI can assist creativity but lacks human emotions, experiences, and intuition essential for true creative expression.


MODULE - 2
1. What are the different types of Generative AI models?
      Generative AI models include Task-Specific GANs, Diffusion Models, Variational Autoencoders (VAEs), Flow Models, and General Generative AI models like GPT and LLaMA. Each type has specific strengths and applications, such as image synthesis, text generation, and data compression.

2. How do GANs work in Generative AI?
      Generative Adversarial Networks (GANs) consist of two neural networks: a generator that creates new data and a discriminator that evaluates its authenticity. The two networks work together to refine the generator’s output, commonly used in image generation and video creation.

3. What is the role of LLaMA in Generative AI?
      LLaMA (Large Language Model Meta AI) is a large language model developed by Meta for various language-related tasks. It competes with models like GPT-3 and is used for generating text, answering questions, and engaging in conversations.

4. How do Generative AI models learn to create new data?
      Generative AI models learn by identifying patterns in vast datasets. During training, these models establish relationships between inputs and outputs, allowing them to generate new data that closely mirrors the original dataset. This is achieved through deep learning architectures like transformers, GANs, and VAEs.

5. What is the significance of GPT-3 in Generative AI?
      GPT-3, developed by OpenAI, is one of the largest and most powerful language models. It uses transformer architectures to perform tasks like translation, summarization, and creative writing, and is widely used in applications like chatbots and content generation.

MODULE - 3
1. What is LangChain?
      LangChain is a tool that helps developers create customized applications using language models. It simplifies complex tasks by linking them into chains, making it easier to integrate data and accelerate development without retraining models.

2. What are some practical use cases of LangChain?
      Chatbots: For multi-step interactions and dynamic responses.
      Content Generation: Automating blog or report creation.
      Data Retrieval: Enhancing search and knowledge systems.
      Document Processing: Summarizing and extracting information.
      Task Automation: Orchestrating workflows across APIs and databases.

3. How does LangChain work? 
      LangChain works by connecting different tasks in a sequence, referred to as "chains." Each chain is composed of links that perform specific actions such as formatting data, retrieving information, or generating content. This modular approach simplifies managing complex processes and enhances flexibility in developing AI applications.

MODULE - 4
1.  What are Diffusion Models?
      Diffusion models are machine learning tools that generate high-quality data by reversing a noise-adding process, commonly used to create lifelike images or coherent text.

2.  How do Diffusion Models work?
      Diffusion models operate in five main steps:
        a)  Data Preparation: Clean, normalize, and augment the data for better learning.
        b)  Adding Noise (Forward Process): Gradually add noise to the data in steps to create complexity.
        c)  Reversing Noise (Reverse Process): Use a neural network to predict and remove noise step by step.
        d)  Neural Network for Reversal: A neural network estimates and removes noise to refine data.
        e)  Model Training: Train the model using Kullback-Leibler (KL) divergence to ensure accurate outputs.

3. What are the applications of Diffusion Models?
      Digital Art Creation: Generate detailed images from simple concepts or text descriptions, aiding artistic expression.
      Graphic Design: Transform rough sketches into polished visuals, speeding up the design process.
      Film and Animation: Create realistic backgrounds or character designs, enhancing visual storytelling.
      Music and Sound Design: Develop unique soundscapes and blend audio tracks innovatively.
      Media and Gaming: Build immersive environments and characters for games and interactive media efficiently.

MODULE - 5
1. What is Transfer Learning?
      Transfer learning is a machine learning technique where a pre-trained model is adapted for a new, related task. It reuses knowledge from the original model, enabling faster training and better accuracy, especially when data is limited.

2.  What is Transfer Learning, and why is it useful?
      Transfer learning adapts a pre-trained model for a new task, saving time and improving accuracy, especially when labeled data is scarce.

3. How is Transfer Learning implemented?
      Transfer learning is implemented by:
          Fine-tuning: Updating specific layers of a pre-trained model for a new task.
          Feature Extraction: Using a pre-trained model's features without further training.
          Multi-task Learning: Training a model on related tasks to share knowledge.

4. What are the common applications of transfer learning?
      Transfer learning is commonly applied in image classification, natural language processing, speech recognition, and medical diagnosis. It helps when there is limited data for a specific task by reusing knowledge from a related domain, improving model performance.

5. What is an example of a transfer learning model?
      A well-known example is BERT (Bidirectional Encoder Representations from Transformers), a pre-trained language model used for NLP tasks like sentiment analysis or text summarization by fine-tuning it on specific datasets.


MODULE - 6
1. What are Bayesian Networks?
      Bayesian networks are graphical models that represent variables as nodes and their dependencies as directed edges. Each node has a probability table that defines the likelihood of the variable, given its parents in the network. These networks are used to understand relationships between variables and uncover patterns, making them useful for analyzing probabilistic dependencies.

2. How do Bayesian Networks work?
      Bayesian networks use Bayesian inference to update predictions with new data, adjusting probabilities based on the relationships between variables. They are built by identifying key variables (nodes) and their connections (edges), with each node having a probability table. The network learns and improves its predictions as it is trained with data.

3. What are some applications of Bayesian Networks?
      Gene Regulatory Networks: Used to model genetic behavior and predict gene interactions.
      Medicine: Helps diagnose and treat diseases by analyzing complex healthcare data.
      Biomonitoring: Interprets data on chemical exposure and its effects on health.
      Document Classification: Automates the categorization of documents for better information retrieval.
      Information Retrieval: Refines search strategies to find relevant resources quickly.
      Semantic Search: Enhances search accuracy by understanding the intent and context behind queries.
      Image Processing: Analyzes and manipulates images for improved quality and feature extraction.
      Spam Filter: Analyzes email patterns to filter out spam effectively.
      Turbo Codes: Used in mobile telephony for efficient data transmission and error correction.
      Systems Biology: Helps infer biological networks and understand molecular interactions.

4. What is the Bayes network formula?
      The Bayes network formula can be written as P(A|B)=P(B|A).P(A)P(B). This equation helps you adjust the likelihood of event A happening when you know event B has occurred. It’s essential for drawing conclusions in Bayesian networks by incorporating new information.

5. What is the difference between CNN and Bayesian?
      Convolutional Neural Networks (CNNs) excel at processing images and recognizing patterns through deep learning. On the other hand, Bayesian networks focus on understanding relationships and uncertainty among variables, allowing for reasoning based on existing knowledge. Each approach is tailored for different challenges in data analysis and modeling.
